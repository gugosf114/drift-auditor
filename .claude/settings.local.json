{
  "permissions": {
    "allow": [
      "Bash(while read commit msg)",
      "Bash(do echo \"=== $msg ===\")",
      "Bash(done)",
      "Bash(python:*)",
      "Bash(dir:*)",
      "mcp__Desktop_Commander__list_directory",
      "Bash(pip install:*)",
      "Bash(tree:*)",
      "Bash(ls:*)",
      "Bash(find:*)",
      "Bash(git add:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nApply 5 targeted fixes: semantic detection, empirical coupling, conflict dedup, batch validator, viz extraction\n\nFix 1: Replace keyword-only omission detection with 3-tier system\n  - Tier 1: Keyword match \\(fast, existing behavior\\)\n  - Tier 2: Sentence embedding cosine similarity \\(all-MiniLM-L6-v2\\)\n  - Tier 3: Barometer-assisted boost \\(existing cross-layer\\)\n  - Falls back gracefully if sentence-transformers not installed\n\nFix 2: Replace hand-picked coupling score weights with empirical v2\n  - Documented rationale for every weight category\n  - Hard/structural/safety constraint detection with distinct weights\n  - Optional batch calibration from real audit data\n\nFix 3: Reduce conflict pair false positives with semantic dedup\n  - Overlap threshold raised from 2 to 3 shared words\n  - Suppress conflicts where cosine similarity >0.6 \\(statements agree\\)\n  - Proximity filter: nearby conflicts get lower severity\n\nFix 4: Add batch_validate.py for verifiable README claims\n  - Reads batch_results/ and batch_results_chatgpt/\n  - Generates batch_summary.json with SHA-256 hashes\n  - Confirms conversation/message counts match README\n\nFix 5: Extract visualization functions into src/visualizations.py\n  - Moves score_color, score_label, render_metric_card, all build_* figs\n  - Adds operator_load_chart for Claude vs ChatGPT comparison\n  - app.py imports from visualizations module\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git push:*)",
      "Bash(where:*)",
      "Bash(py:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nRedesign dashboard UI for enterprise compliance audiences\n\nComplete rewrite of app.py \\(929 lines\\) and visualizations.py \\(504 lines\\)\nwith professional dark theme, 5-tab layout \\(Dashboard, Instruction\nLifecycle, Operator Load, Detailed Flags, Export\\), hero metric cards,\nDrift Barometer timeline, Instruction Decay Curves, filterable flags,\ncross-model comparison, and purple brand palette. Targets VP-level\ncompliance officers and AI safety teams.\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(powershell -Command:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nAdd Live Analysis mode and Regression Analysis to dashboard\n\nNew sidebar mode selector with three modes:\n- File Analysis \\(existing\\): upload/sample conversation analysis\n- Live Analysis: paste-as-you-go with OLI trending over successive\n  pastes, real-time drift timeline, flag breakdown\n- Regression: scatter plots from 512 batch conversations showing\n  conversation length vs drift, instruction count vs drift score,\n  model type vs correction failure rate, flag accumulation rates,\n  with trendlines and Pearson correlations\n\nAlso adds .claude/ and nul to .gitignore.\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFix regression mode: DataFrame column access, move glob import to top\n\n- Replace df.get\\(\\) with proper fillna/clip for commission_flags,\n  omission_flags, corrections_failed, corrections_total columns\n- Move ''import glob as glob_mod'' to module top so it''s available\n  in both Regression and File Analysis modes\n- Tested against all 512 batch conversations â€” all computations pass\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git commit:*)"
    ]
  }
}
