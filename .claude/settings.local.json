{
  "permissions": {
    "allow": [
      "Bash(while read commit msg)",
      "Bash(do echo \"=== $msg ===\")",
      "Bash(done)",
      "Bash(python:*)",
      "Bash(dir:*)",
      "mcp__Desktop_Commander__list_directory",
      "Bash(pip install:*)",
      "Bash(tree:*)",
      "Bash(ls:*)",
      "Bash(find:*)",
      "Bash(git add:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nApply 5 targeted fixes: semantic detection, empirical coupling, conflict dedup, batch validator, viz extraction\n\nFix 1: Replace keyword-only omission detection with 3-tier system\n  - Tier 1: Keyword match \\(fast, existing behavior\\)\n  - Tier 2: Sentence embedding cosine similarity \\(all-MiniLM-L6-v2\\)\n  - Tier 3: Barometer-assisted boost \\(existing cross-layer\\)\n  - Falls back gracefully if sentence-transformers not installed\n\nFix 2: Replace hand-picked coupling score weights with empirical v2\n  - Documented rationale for every weight category\n  - Hard/structural/safety constraint detection with distinct weights\n  - Optional batch calibration from real audit data\n\nFix 3: Reduce conflict pair false positives with semantic dedup\n  - Overlap threshold raised from 2 to 3 shared words\n  - Suppress conflicts where cosine similarity >0.6 \\(statements agree\\)\n  - Proximity filter: nearby conflicts get lower severity\n\nFix 4: Add batch_validate.py for verifiable README claims\n  - Reads batch_results/ and batch_results_chatgpt/\n  - Generates batch_summary.json with SHA-256 hashes\n  - Confirms conversation/message counts match README\n\nFix 5: Extract visualization functions into src/visualizations.py\n  - Moves score_color, score_label, render_metric_card, all build_* figs\n  - Adds operator_load_chart for Claude vs ChatGPT comparison\n  - app.py imports from visualizations module\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git push:*)",
      "Bash(where:*)",
      "Bash(py:*)"
    ]
  }
}
